---
title: "Mulivariate XGBoost Model"
subtitle: "Predicting COVID-19 Deaths (STAT 390)" 
author: "Ryan Nguyen"

format:
  html:
    toc: true
    embed-resources: true
    link-external-newwindow: true
    code-fold: true
    
output:
  html_document:
    code_folding: hide

execute:
  warning: false

from: markdown+emoji 
---

## 1. Import Libraries & Set Seed
```{r}
library(forecast)
library(tseries)
library(tidyverse)
library(tidymodels)
library(kableExtra)
library(modeltime)
library(prophet)
library(timetk)
library(Metrics)
library(zoo)
library(MLmetrics)
library(xgboost)

set.seed(123)

```


## 2. Pull Data
```{r}
selected_deaths <- read_csv("data/finaldata_selectedfeatures.csv")
```



## 3. Train Test Split
```{r}
# Splitting into testing and training by year
train_data  <- selected_deaths %>% 
  filter(year != 2023)

test_data <- selected_deaths %>%
  filter(year == 2023)

# Converting data into xg boost matrices
train_matrix <- train_data %>% 
  select(-c(date, covid_19_deaths)) %>% 
  as.matrix()

test_matrix <- test_data %>% 
  select(-c(date, covid_19_deaths)) %>% 
  as.matrix() %>% 
  xgb.DMatrix()

# creating target vector
targets <- train_data$covid_19_deaths
```

## 4. Control Grid
```{r}
xgb_trcontrol <- caret::trainControl(
   method = "cv", 
   number = 5,
   allowParallel = TRUE, 
   verboseIter = FALSE, 
   returnData = FALSE
)

xgb_grid <- base::expand.grid(
   list(
    nrounds = c(100, 200),
    max_depth = c(10, 15, 20), # maximum depth of a tree
    colsample_bytree = seq(0.5), # subsample ratio of columns when construction each tree
    eta = 0.1, # learning rate
    gamma = 0, # minimum loss reduction
    min_child_weight = 1,  # minimum sum of instance weight (hessian) needed ina child
    subsample = 1 # subsample ratio of the training instances
))
```


```{r eval = FALSE}
xgb_model <- caret::train(
   train_matrix, targets,
   trControl = xgb_trcontrol,
   tuneGrid = xgb_grid,
   method = "xgbTree",
   nthread = 1
)

save(xgb_model, file = "results/multi_xgboost.rda")
```

## 5. Check Best Model
```{r}
load("results/multi_xgboost.rda")

xgb_model$bestTune
```

## 6. Perform Forecast
```{r}
xgb_pred <- xgb_model %>% stats::predict(test_data)
```

## 7. Model Plot
```{r}
# prediction on a train set
fitted <- xgb_model %>%
    stats::predict(train_data)

train_predictions <- cbind(fitted, train_data)
test_predictions <-cbind(xgb_pred, test_data) %>% 
  rename(fitted = xgb_pred)
full_pred <- rbind(train_predictions, test_predictions)

```

```{r}

test_predictions %>% 
  ggplot() +
  geom_line(aes(x = date, y = fitted, color = "blue")) +
  geom_point(aes(x = date, y = fitted, color = "blue"), alpha = 0.2) +
  geom_line(aes(x = date, y = covid_19_deaths, color = "red"), alpha = 0.7) +
  geom_point(aes(x = date, y = covid_19_deaths, color = "red"), alpha = 0.2) +
  scale_color_manual(name="Value", values = c("blue", "red"), labels = c("Predicted", "Actual")) +
  labs(title = "XGBoost Forecast")
```


## 7. Model Performance
```{r}
# Check MAE value
xgboost_mae <- mae(test_data$covid_19_deaths, xgb_pred)
print(paste("The MAE for the XGBoost model is", xgboost_mae))

# Check MASE value
xgboost_mase <- mase(test_data$covid_19_deaths, xgb_pred)
print(paste("The MASE for the XGBoost model is", xgboost_mase))
```


